{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87451e54",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-10-01T15:32:03.700685Z",
     "iopub.status.busy": "2023-10-01T15:32:03.700228Z",
     "iopub.status.idle": "2023-10-01T15:32:04.412751Z",
     "shell.execute_reply": "2023-10-01T15:32:04.411506Z"
    },
    "papermill": {
     "duration": 0.720336,
     "end_time": "2023-10-01T15:32:04.414375",
     "exception": false,
     "start_time": "2023-10-01T15:32:03.694039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UYARI ENGELLEYİCİ\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "print(\"UYARI ENGELLEYİCİ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5d920a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-01T15:32:04.425358Z",
     "iopub.status.busy": "2023-10-01T15:32:04.424386Z",
     "iopub.status.idle": "2023-10-01T15:32:04.545330Z",
     "shell.execute_reply": "2023-10-01T15:32:04.544480Z"
    },
    "papermill": {
     "duration": 0.127412,
     "end_time": "2023-10-01T15:32:04.546864",
     "exception": false,
     "start_time": "2023-10-01T15:32:04.419452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOSYA YOL KODLARI\n"
     ]
    }
   ],
   "source": [
    "filepath = '/kaggle/input/commonlit-evaluate-student-summaries'\n",
    "\n",
    "prompts_test = pd.read_csv(os.path.join(filepath, 'prompts_test.csv'))\n",
    "prompts_train = pd.read_csv(os.path.join(filepath, 'prompts_train.csv'))\n",
    "sub = pd.read_csv(os.path.join(filepath, 'sample_submission.csv'))\n",
    "summaries_test = pd.read_csv(os.path.join(filepath, 'summaries_test.csv'))\n",
    "summaries_train = pd.read_csv(os.path.join(filepath, 'summaries_train.csv'))\n",
    "print(\"DOSYA YOL KODLARI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "883acffc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-01T15:32:04.556724Z",
     "iopub.status.busy": "2023-10-01T15:32:04.556049Z",
     "iopub.status.idle": "2023-10-01T15:32:04.565984Z",
     "shell.execute_reply": "2023-10-01T15:32:04.565019Z"
    },
    "papermill": {
     "duration": 0.015937,
     "end_time": "2023-10-01T15:32:04.567255",
     "exception": false,
     "start_time": "2023-10-01T15:32:04.551318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The third wave was an experimentto see how people reacted to a new one leader government. It gained popularity as people wanted to try new things. The students follow anything that is said and start turning on eachother to gain higher power. They had to stop the experement as too many people got to radical with it blindly following there leader\n"
     ]
    }
   ],
   "source": [
    "print(summaries_train[\"text\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b78cb249",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-01T15:32:04.577737Z",
     "iopub.status.busy": "2023-10-01T15:32:04.577249Z",
     "iopub.status.idle": "2023-10-01T15:32:04.595125Z",
     "shell.execute_reply": "2023-10-01T15:32:04.593811Z"
    },
    "papermill": {
     "duration": 0.02548,
     "end_time": "2023-10-01T15:32:04.597237",
     "exception": false,
     "start_time": "2023-10-01T15:32:04.571757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "desired_length = 20\n",
    "filtered_summaries_train = pd.concat([group.sample(desired_length) for _, group in summaries_train.groupby('prompt_id')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8746553f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-01T15:32:04.606890Z",
     "iopub.status.busy": "2023-10-01T15:32:04.606623Z",
     "iopub.status.idle": "2023-10-01T15:32:04.625488Z",
     "shell.execute_reply": "2023-10-01T15:32:04.624495Z"
    },
    "papermill": {
     "duration": 0.025394,
     "end_time": "2023-10-01T15:32:04.627008",
     "exception": false,
     "start_time": "2023-10-01T15:32:04.601614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2171</th>\n",
       "      <td>4d67a6099fc8</td>\n",
       "      <td>39c16e</td>\n",
       "      <td>One element of a tragedy would b e that the pl...</td>\n",
       "      <td>-0.308448</td>\n",
       "      <td>0.048171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6666</th>\n",
       "      <td>eedaf3955aa0</td>\n",
       "      <td>39c16e</td>\n",
       "      <td>You must have a good plot not one that makes t...</td>\n",
       "      <td>0.376374</td>\n",
       "      <td>0.463619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>3795b81d1445</td>\n",
       "      <td>39c16e</td>\n",
       "      <td>A good tragedy should feature  a change of for...</td>\n",
       "      <td>-1.204574</td>\n",
       "      <td>-1.169784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3211</th>\n",
       "      <td>71beea5e19f1</td>\n",
       "      <td>39c16e</td>\n",
       "      <td>The 3 elements are the plot, the character, an...</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.380538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4180</th>\n",
       "      <td>93c42389c68c</td>\n",
       "      <td>39c16e</td>\n",
       "      <td>Three elements of an ideal tragedy are focused...</td>\n",
       "      <td>-0.602425</td>\n",
       "      <td>-1.039843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6038</th>\n",
       "      <td>d746eb05063b</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>The way's they dealt with spoiled meat is by f...</td>\n",
       "      <td>-0.731230</td>\n",
       "      <td>-0.833467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>3b6e444215dc</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>Paragraph 2 says that the factory would \"rub t...</td>\n",
       "      <td>-0.002466</td>\n",
       "      <td>-0.045439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3018</th>\n",
       "      <td>6afe80da9e2c</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>The ways the factory would cover up the spoile...</td>\n",
       "      <td>0.404076</td>\n",
       "      <td>-0.755297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5920</th>\n",
       "      <td>d293370d610d</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>the factories would can it or turn it into sau...</td>\n",
       "      <td>-0.393310</td>\n",
       "      <td>0.627128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7138</th>\n",
       "      <td>fec7e0e788b2</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>One way they covered up meat is they would rub...</td>\n",
       "      <td>0.297031</td>\n",
       "      <td>-0.168734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        student_id prompt_id  \\\n",
       "2171  4d67a6099fc8    39c16e   \n",
       "6666  eedaf3955aa0    39c16e   \n",
       "1543  3795b81d1445    39c16e   \n",
       "3211  71beea5e19f1    39c16e   \n",
       "4180  93c42389c68c    39c16e   \n",
       "...            ...       ...   \n",
       "6038  d746eb05063b    ebad26   \n",
       "1653  3b6e444215dc    ebad26   \n",
       "3018  6afe80da9e2c    ebad26   \n",
       "5920  d293370d610d    ebad26   \n",
       "7138  fec7e0e788b2    ebad26   \n",
       "\n",
       "                                                   text   content   wording  \n",
       "2171  One element of a tragedy would b e that the pl... -0.308448  0.048171  \n",
       "6666  You must have a good plot not one that makes t...  0.376374  0.463619  \n",
       "1543  A good tragedy should feature  a change of for... -1.204574 -1.169784  \n",
       "3211  The 3 elements are the plot, the character, an...  0.205683  0.380538  \n",
       "4180  Three elements of an ideal tragedy are focused... -0.602425 -1.039843  \n",
       "...                                                 ...       ...       ...  \n",
       "6038  The way's they dealt with spoiled meat is by f... -0.731230 -0.833467  \n",
       "1653  Paragraph 2 says that the factory would \"rub t... -0.002466 -0.045439  \n",
       "3018  The ways the factory would cover up the spoile...  0.404076 -0.755297  \n",
       "5920  the factories would can it or turn it into sau... -0.393310  0.627128  \n",
       "7138  One way they covered up meat is they would rub...  0.297031 -0.168734  \n",
       "\n",
       "[80 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_summaries_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a5b2ed",
   "metadata": {
    "papermill": {
     "duration": 0.00409,
     "end_time": "2023-10-01T15:32:04.635939",
     "exception": false,
     "start_time": "2023-10-01T15:32:04.631849",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Verileri parçalara böl ki işin uzun sürmesin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87558a06",
   "metadata": {
    "papermill": {
     "duration": 0.003975,
     "end_time": "2023-10-01T15:32:04.644137",
     "exception": false,
     "start_time": "2023-10-01T15:32:04.640162",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ****Tokenizasyon****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b02bc395",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-01T15:32:04.654034Z",
     "iopub.status.busy": "2023-10-01T15:32:04.653317Z",
     "iopub.status.idle": "2023-10-01T15:32:30.619231Z",
     "shell.execute_reply": "2023-10-01T15:32:30.618099Z"
    },
    "papermill": {
     "duration": 25.972726,
     "end_time": "2023-10-01T15:32:30.620923",
     "exception": false,
     "start_time": "2023-10-01T15:32:04.648197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [Errno -3] Temporary\n",
      "[nltk_data]     failure in name resolution>\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# NLTK'den tokenizer'ı yükle\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Tokenizasyon işlemi\n",
    "filtered_summaries_train['tokenized_text'] = filtered_summaries_train['text'].apply(lambda x: word_tokenize(x))\n",
    "prompts_test['prompt_text'] = prompts_test['prompt_text'].apply(lambda x: word_tokenize(x))\n",
    "summaries_test['text'] = summaries_test['text'].apply(lambda x: word_tokenize(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a88af496",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-01T15:32:30.631797Z",
     "iopub.status.busy": "2023-10-01T15:32:30.631509Z",
     "iopub.status.idle": "2023-10-01T15:32:30.637013Z",
     "shell.execute_reply": "2023-10-01T15:32:30.635363Z"
    },
    "papermill": {
     "duration": 0.013009,
     "end_time": "2023-10-01T15:32:30.638821",
     "exception": false,
     "start_time": "2023-10-01T15:32:30.625812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', '3', 'elements', 'are', 'the', 'plot', ',', 'the', 'character', ',', 'and', 'the', 'use', 'of', 'words', '.', 'It', 'should', 'be', 'something', 'people', 'can', 'relate', 'to', '.', 'The', 'story', 'should', 'be', 'interesting', '.', 'You', 'ca', \"n't\", 'do', 'this', 'without', 'the', 'character', ',', 'plot', 'and', 'words', '.', 'The', 'character', 'is', 'not', 'good', 'or', 'bad', 'but', 'ha', 'had', 'a', 'rough', 'life', '.', 'The', 'plot', 'is', 'relatable', 'to', 'the', 'reader', 'because', 'it', 'requres', 'a', 'falling', 'of', 'the', 'man', '.', 'The', 'words', 'bring', 'it', 'to', 'life', '.']\n"
     ]
    }
   ],
   "source": [
    "print(filtered_summaries_train[\"tokenized_text\"].iloc[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37657498",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-01T15:32:30.649559Z",
     "iopub.status.busy": "2023-10-01T15:32:30.649169Z",
     "iopub.status.idle": "2023-10-01T15:32:30.655277Z",
     "shell.execute_reply": "2023-10-01T15:32:30.654564Z"
    },
    "papermill": {
     "duration": 0.013402,
     "end_time": "2023-10-01T15:32:30.656798",
     "exception": false,
     "start_time": "2023-10-01T15:32:30.643396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The 3 elements are the plot, the character, and the use of words. It should be something people can relate to. The story should be interesting. You can't do this without the character, plot and words. The character is not good or bad but ha had a rough life. The plot is relatable to the reader because it requres a falling of the man. The words bring it to life.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_summaries_train[\"text\"].iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f7db540",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-01T15:32:30.667679Z",
     "iopub.status.busy": "2023-10-01T15:32:30.667303Z",
     "iopub.status.idle": "2023-10-01T15:32:30.678841Z",
     "shell.execute_reply": "2023-10-01T15:32:30.677841Z"
    },
    "papermill": {
     "duration": 0.018928,
     "end_time": "2023-10-01T15:32:30.680545",
     "exception": false,
     "start_time": "2023-10-01T15:32:30.661617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2171</th>\n",
       "      <td>4d67a6099fc8</td>\n",
       "      <td>39c16e</td>\n",
       "      <td>One element of a tragedy would b e that the pl...</td>\n",
       "      <td>-0.308448</td>\n",
       "      <td>0.048171</td>\n",
       "      <td>[One, element, of, a, tragedy, would, b, e, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6666</th>\n",
       "      <td>eedaf3955aa0</td>\n",
       "      <td>39c16e</td>\n",
       "      <td>You must have a good plot not one that makes t...</td>\n",
       "      <td>0.376374</td>\n",
       "      <td>0.463619</td>\n",
       "      <td>[You, must, have, a, good, plot, not, one, tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>3795b81d1445</td>\n",
       "      <td>39c16e</td>\n",
       "      <td>A good tragedy should feature  a change of for...</td>\n",
       "      <td>-1.204574</td>\n",
       "      <td>-1.169784</td>\n",
       "      <td>[A, good, tragedy, should, feature, a, change,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3211</th>\n",
       "      <td>71beea5e19f1</td>\n",
       "      <td>39c16e</td>\n",
       "      <td>The 3 elements are the plot, the character, an...</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.380538</td>\n",
       "      <td>[The, 3, elements, are, the, plot, ,, the, cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4180</th>\n",
       "      <td>93c42389c68c</td>\n",
       "      <td>39c16e</td>\n",
       "      <td>Three elements of an ideal tragedy are focused...</td>\n",
       "      <td>-0.602425</td>\n",
       "      <td>-1.039843</td>\n",
       "      <td>[Three, elements, of, an, ideal, tragedy, are,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        student_id prompt_id  \\\n",
       "2171  4d67a6099fc8    39c16e   \n",
       "6666  eedaf3955aa0    39c16e   \n",
       "1543  3795b81d1445    39c16e   \n",
       "3211  71beea5e19f1    39c16e   \n",
       "4180  93c42389c68c    39c16e   \n",
       "\n",
       "                                                   text   content   wording  \\\n",
       "2171  One element of a tragedy would b e that the pl... -0.308448  0.048171   \n",
       "6666  You must have a good plot not one that makes t...  0.376374  0.463619   \n",
       "1543  A good tragedy should feature  a change of for... -1.204574 -1.169784   \n",
       "3211  The 3 elements are the plot, the character, an...  0.205683  0.380538   \n",
       "4180  Three elements of an ideal tragedy are focused... -0.602425 -1.039843   \n",
       "\n",
       "                                         tokenized_text  \n",
       "2171  [One, element, of, a, tragedy, would, b, e, th...  \n",
       "6666  [You, must, have, a, good, plot, not, one, tha...  \n",
       "1543  [A, good, tragedy, should, feature, a, change,...  \n",
       "3211  [The, 3, elements, are, the, plot, ,, the, cha...  \n",
       "4180  [Three, elements, of, an, ideal, tragedy, are,...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_summaries_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd498a14",
   "metadata": {
    "papermill": {
     "duration": 0.004518,
     "end_time": "2023-10-01T15:32:30.690203",
     "exception": false,
     "start_time": "2023-10-01T15:32:30.685685",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Metin Temizliği**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a78aa32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-01T15:32:30.701115Z",
     "iopub.status.busy": "2023-10-01T15:32:30.700808Z",
     "iopub.status.idle": "2023-10-01T15:32:54.751141Z",
     "shell.execute_reply": "2023-10-01T15:32:54.749725Z"
    },
    "papermill": {
     "duration": 24.057983,
     "end_time": "2023-10-01T15:32:54.752856",
     "exception": false,
     "start_time": "2023-10-01T15:32:30.694873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno -3]\n",
      "[nltk_data]     Temporary failure in name resolution>\n",
      "2171    one element tragedy would b e plot starts good...\n",
      "6666    must good plot one makes reader feel pity main...\n",
      "1543    good tragedy feature change fortune prosperity...\n",
      "3211    3 elements plot  character  use words  somethi...\n",
      "4180    three elements ideal tragedy focused complex i...\n",
      "                              ...                        \n",
      "6038    way s dealt spoiled meat first would go take m...\n",
      "1653    paragraph 2 says factory would  rub meat ons s...\n",
      "3018    ways factory would cover spoiled meat  would p...\n",
      "5920    factories would turn sauges  also put spoiled ...\n",
      "7138    one way covered meat would rub soda hide smell...\n",
      "Name: cleaned_text, Length: 80, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "# NLTK stopwords verilerini indirin\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Temizleme işlemlerini uygulama fonksiyonu\n",
    "def preprocess_text(tokenized_text):\n",
    "    # Her bir kelimeyi temizle\n",
    "    cleaned_words = []\n",
    "    for word in tokenized_text:\n",
    "        # Küçük harfe dönüştürme\n",
    "        word = word.lower()\n",
    "        # Noktalama işaretlerini boşlukla değiştirme\n",
    "        word = re.sub(r'[^\\w\\s]', ' ', word)\n",
    "        # Gereksiz boşlukları kaldırma\n",
    "        word = re.sub(r'\\s+', ' ', word)\n",
    "        # Stopwords'leri kaldırma\n",
    "        if word not in stop_words:\n",
    "            cleaned_words.append(word)\n",
    "    return ' '.join(cleaned_words)\n",
    "\n",
    "# Tokenleştirilmiş metinleri temizleme\n",
    "filtered_summaries_train['cleaned_text'] = filtered_summaries_train['tokenized_text'].apply(preprocess_text)\n",
    "prompts_test['prompt_text'] = prompts_test['prompt_text'].apply(preprocess_text)\n",
    "summaries_test['text'] = summaries_test['text'].apply(preprocess_text)\n",
    "\n",
    "# Noktalama işaretlerini boşlukla değiştirme\n",
    "filtered_summaries_train['cleaned_text'] = filtered_summaries_train['cleaned_text'].str.replace('[^\\w\\s]', '')\n",
    "prompts_test['prompt_text'] = prompts_test['prompt_text'].str.replace('[^\\w\\s]', '')\n",
    "summaries_test['text'] = summaries_test['text'].str.replace('[^\\w\\s]', '')\n",
    "\n",
    "# ŞİMDİ BOŞLUKLARI KALDIRRRR HAYDİİİİİİİİİİİ\n",
    "filtered_summaries_train['cleaned_text'] = filtered_summaries_train['cleaned_text'].str.replace('\\s+', '')\n",
    "prompts_test['prompt_text'] = prompts_test['prompt_text'].str.replace('\\s+', '')\n",
    "summaries_test['text'] = summaries_test['text'].str.replace('\\s+', '')\n",
    "\n",
    "#Bişey deniyorum\n",
    "filtered_summaries_train['cleaned_text'] = filtered_summaries_train['cleaned_text'].str.replace('  ', ' ')\n",
    "prompts_test['prompt_text'] = prompts_test['prompt_text'].str.replace('  ', ' ')\n",
    "summaries_test['text'] = summaries_test['text'].str.replace('  ', ' ')\n",
    "\n",
    "filtered_summaries_train['cleaned_text'] = filtered_summaries_train['cleaned_text'].str.replace('   ', ' ')\n",
    "prompts_test['prompt_text'] = prompts_test['prompt_text'].str.replace('   ', ' ')\n",
    "summaries_test['text'] = summaries_test['text'].str.replace('   ', ' ')\n",
    "\n",
    "filtered_summaries_train['cleaned_text'] = filtered_summaries_train['cleaned_text'].str.replace('    ', ' ')\n",
    "prompts_test['prompt_text'] = prompts_test['prompt_text'].str.replace('    ', ' ')\n",
    "summaries_test['text'] = summaries_test['text'].str.replace('    ', ' ')\n",
    "\n",
    "# Temizlenmiş verileri gösterme\n",
    "print(filtered_summaries_train['cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b81a0f28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-01T15:32:54.763610Z",
     "iopub.status.busy": "2023-10-01T15:32:54.763326Z",
     "iopub.status.idle": "2023-10-01T15:32:54.767321Z",
     "shell.execute_reply": "2023-10-01T15:32:54.766407Z"
    },
    "papermill": {
     "duration": 0.010759,
     "end_time": "2023-10-01T15:32:54.768633",
     "exception": false,
     "start_time": "2023-10-01T15:32:54.757874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 elements plot  character  use words  something people relate  story interesting  ca n t without character  plot words  character good bad ha rough life  plot relatable reader requres falling man  words bring life \n"
     ]
    }
   ],
   "source": [
    "print(filtered_summaries_train[\"cleaned_text\"].iloc[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "445c9c90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-01T15:32:54.780667Z",
     "iopub.status.busy": "2023-10-01T15:32:54.780255Z",
     "iopub.status.idle": "2023-10-01T15:32:54.785644Z",
     "shell.execute_reply": "2023-10-01T15:32:54.784464Z"
    },
    "papermill": {
     "duration": 0.013364,
     "end_time": "2023-10-01T15:32:54.787338",
     "exception": false,
     "start_time": "2023-10-01T15:32:54.773974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 3 elements are the plot, the character, and the use of words. It should be something people can relate to. The story should be interesting. You can't do this without the character, plot and words. The character is not good or bad but ha had a rough life. The plot is relatable to the reader because it requres a falling of the man. The words bring it to life.\n"
     ]
    }
   ],
   "source": [
    "print(filtered_summaries_train[\"text\"].iloc[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c8407b",
   "metadata": {
    "papermill": {
     "duration": 0.004482,
     "end_time": "2023-10-01T15:32:54.796889",
     "exception": false,
     "start_time": "2023-10-01T15:32:54.792407",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## ikinci aşama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0db66d9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-01T15:32:54.807549Z",
     "iopub.status.busy": "2023-10-01T15:32:54.807214Z",
     "iopub.status.idle": "2023-10-01T15:32:54.813079Z",
     "shell.execute_reply": "2023-10-01T15:32:54.811734Z"
    },
    "papermill": {
     "duration": 0.013207,
     "end_time": "2023-10-01T15:32:54.814819",
     "exception": false,
     "start_time": "2023-10-01T15:32:54.801612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1070\n"
     ]
    }
   ],
   "source": [
    "# \"text\" sütunundaki tüm satırları birleştirip tek bir metin oluşturun\n",
    "all_text = ' '.join(filtered_summaries_train['cleaned_text'])\n",
    "\n",
    "# Metni boşluklardan bölerek kelimeleri ayırın ve bir liste oluşturun\n",
    "words = all_text.split()\n",
    "\n",
    "# Kelimelerin benzersiz (unique) olmasını sağlamak için bir küme (set) oluşturun\n",
    "unique_words_list = list(set(words))\n",
    "\n",
    "# Benzersiz kelimeleri görüntüleyin\n",
    "print(len(unique_words_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc893e5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-01T15:32:54.826342Z",
     "iopub.status.busy": "2023-10-01T15:32:54.826067Z",
     "iopub.status.idle": "2023-10-01T15:32:54.831303Z",
     "shell.execute_reply": "2023-10-01T15:32:54.830088Z"
    },
    "papermill": {
     "duration": 0.013571,
     "end_time": "2023-10-01T15:32:54.833542",
     "exception": false,
     "start_time": "2023-10-01T15:32:54.819971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['order', 'rubbing', 'donations', 'mixing', 'card', 'middel', 'realizing', 'isis', 'pickleing', 'ratting', 'quality', 'rich', 'men', 'experiment', 'lot', 'responsible', 'better', 'lay', 'say', 'depravity']\n"
     ]
    }
   ],
   "source": [
    "# 11. kelime ile 20. kelime arasındaki benzersiz kelimeleri görüntülemek için\n",
    "print(unique_words_list[150:170])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66f737fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-01T15:32:54.845822Z",
     "iopub.status.busy": "2023-10-01T15:32:54.845272Z",
     "iopub.status.idle": "2023-10-01T15:32:54.877665Z",
     "shell.execute_reply": "2023-10-01T15:32:54.876717Z"
    },
    "papermill": {
     "duration": 0.041002,
     "end_time": "2023-10-01T15:32:54.880205",
     "exception": false,
     "start_time": "2023-10-01T15:32:54.839203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Başarılı\n"
     ]
    }
   ],
   "source": [
    "# Birden fazla kelimeyi düzeltmek için her bir düzeltmeyi ayrı satırlarda tanımlayın\n",
    "\n",
    "corrections = {\n",
    "    \"structuree\": \"structure\",\n",
    "    \"emploees\": \"employees\",\n",
    "    \"governemtn\": \"government\",\n",
    "    \"bellieved\": \"believed\",\n",
    "    \"nuaseating\":\"nauseating\",\n",
    "    \"extact\":\"extract\",\n",
    "    \"valubule\":\"valuable\",\n",
    "    \"reaso\":\"reason\",\n",
    "    \"figting\":\"fighting\",\n",
    "    \"complx\":\"complex\",\n",
    "    \"sonstructed\":\"constructed\",\n",
    "    \"differeny\":\"different\",\n",
    "    \"instert\":\"insert\",\n",
    "    \"experiemnt\":\"experiment\",\n",
    "    \"folloeing\":\"following\",\n",
    "    \"behaivior\":\"behavior\",\n",
    "    \"beggng\":\"begging\",\n",
    "    \"middl\":\"middle\",\n",
    "    \"expirament\":\"experiment\",\n",
    "    \"shoild\":\"should\",\n",
    "    \"supposted\":\"supposed\",\n",
    "    \"desissions\":\"decisions\",\n",
    "    \"movemnet\":\"movement\",\n",
    "    \"controllled\":\"controlled\",\n",
    "    \"gorvernemt\":\"government\",\n",
    "    \"afer\":\"after\",\n",
    "    \"succesfull\":\"successful\",\n",
    "    \"pharoaohs\":\"pharaohs\",\n",
    "    \"pharoras\":\"pharaohs\",\n",
    "    \"quaility\":\"quality\",\n",
    "    \"tradedy\":\"tragedy\",\n",
    "    \"wokers\":\"workers\",\n",
    "    \"exampl\":\"example\",\n",
    "    \"classś\":\"class\",\n",
    "    \"includs\":\"includes\",\n",
    "    \"susage\":\"sausage\",\n",
    "    \"mobilty\":\"mobility\",\n",
    "    \"saddness\":\"sadness\",\n",
    "    \"sinckair\":\"sinclair\",\n",
    "    \"artile\":\"article\",\n",
    "    \"craftsmem\":\"craftsmen\",\n",
    "    \"charactor\":\"character\",\n",
    "    \"thorught\":\"through\",\n",
    "    \"aviod\":\"avoid\",\n",
    "    \"betweem\":\"between\",\n",
    "    \"endof\":\"end of\",\n",
    "    \"perceft\":\"perfect\",\n",
    "    \"glycerince\":\"glycerine\",\n",
    "    \"ful\":\"full\"\n",
    "}\n",
    "\n",
    "# Her düzeltmeyi sırayla uygulayın\n",
    "for old_word, new_word in corrections.items():\n",
    "    filtered_summaries_train['cleaned_text'] = filtered_summaries_train['cleaned_text'].str.replace(old_word, new_word)\n",
    "\n",
    "for old_word, new_word in corrections.items():\n",
    "    filtered_summaries_train['text'] = filtered_summaries_train['text'].str.replace(old_word, new_word)\n",
    "\n",
    "# Sütunun güncellendiğini kontrol etmek için ilk 10 satırı görüntüleyebilirsiniz\n",
    "print(\"Başarılı\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "065845ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-01T15:32:54.892150Z",
     "iopub.status.busy": "2023-10-01T15:32:54.891599Z",
     "iopub.status.idle": "2023-10-01T15:32:54.903225Z",
     "shell.execute_reply": "2023-10-01T15:32:54.902352Z"
    },
    "papermill": {
     "duration": 0.019168,
     "end_time": "2023-10-01T15:32:54.904842",
     "exception": false,
     "start_time": "2023-10-01T15:32:54.885674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2171</th>\n",
       "      <td>4d67a6099fc8</td>\n",
       "      <td>39c16e</td>\n",
       "      <td>One element of a tragedy would b e that the pl...</td>\n",
       "      <td>-0.308448</td>\n",
       "      <td>0.048171</td>\n",
       "      <td>[One, element, of, a, tragedy, would, b, e, th...</td>\n",
       "      <td>one element tragedy would b e plot starts good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6666</th>\n",
       "      <td>eedaf3955aa0</td>\n",
       "      <td>39c16e</td>\n",
       "      <td>You must have a good plot not one that makes t...</td>\n",
       "      <td>0.376374</td>\n",
       "      <td>0.463619</td>\n",
       "      <td>[You, must, have, a, good, plot, not, one, tha...</td>\n",
       "      <td>must good plot one makes reader feel pity main...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>3795b81d1445</td>\n",
       "      <td>39c16e</td>\n",
       "      <td>A good tragedy should feature  a change of for...</td>\n",
       "      <td>-1.204574</td>\n",
       "      <td>-1.169784</td>\n",
       "      <td>[A, good, tragedy, should, feature, a, change,...</td>\n",
       "      <td>good tragedy feature change fortune prosperity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3211</th>\n",
       "      <td>71beea5e19f1</td>\n",
       "      <td>39c16e</td>\n",
       "      <td>The 3 elements are the plot, the character, an...</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.380538</td>\n",
       "      <td>[The, 3, elements, are, the, plot, ,, the, cha...</td>\n",
       "      <td>3 elements plot  character  use words  somethi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4180</th>\n",
       "      <td>93c42389c68c</td>\n",
       "      <td>39c16e</td>\n",
       "      <td>Three elements of an ideal tragedy are focused...</td>\n",
       "      <td>-0.602425</td>\n",
       "      <td>-1.039843</td>\n",
       "      <td>[Three, elements, of, an, ideal, tragedy, are,...</td>\n",
       "      <td>three elements ideal tragedy focused complex i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        student_id prompt_id  \\\n",
       "2171  4d67a6099fc8    39c16e   \n",
       "6666  eedaf3955aa0    39c16e   \n",
       "1543  3795b81d1445    39c16e   \n",
       "3211  71beea5e19f1    39c16e   \n",
       "4180  93c42389c68c    39c16e   \n",
       "\n",
       "                                                   text   content   wording  \\\n",
       "2171  One element of a tragedy would b e that the pl... -0.308448  0.048171   \n",
       "6666  You must have a good plot not one that makes t...  0.376374  0.463619   \n",
       "1543  A good tragedy should feature  a change of for... -1.204574 -1.169784   \n",
       "3211  The 3 elements are the plot, the character, an...  0.205683  0.380538   \n",
       "4180  Three elements of an ideal tragedy are focused... -0.602425 -1.039843   \n",
       "\n",
       "                                         tokenized_text  \\\n",
       "2171  [One, element, of, a, tragedy, would, b, e, th...   \n",
       "6666  [You, must, have, a, good, plot, not, one, tha...   \n",
       "1543  [A, good, tragedy, should, feature, a, change,...   \n",
       "3211  [The, 3, elements, are, the, plot, ,, the, cha...   \n",
       "4180  [Three, elements, of, an, ideal, tragedy, are,...   \n",
       "\n",
       "                                           cleaned_text  \n",
       "2171  one element tragedy would b e plot starts good...  \n",
       "6666  must good plot one makes reader feel pity main...  \n",
       "1543  good tragedy feature change fortune prosperity...  \n",
       "3211  3 elements plot  character  use words  somethi...  \n",
       "4180  three elements ideal tragedy focused complex i...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_summaries_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a8d320",
   "metadata": {
    "papermill": {
     "duration": 0.004806,
     "end_time": "2023-10-01T15:32:54.914965",
     "exception": false,
     "start_time": "2023-10-01T15:32:54.910159",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **BİR SONRAKİ TURDA LEMMATİZASYON**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f091410d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-01T15:32:54.926306Z",
     "iopub.status.busy": "2023-10-01T15:32:54.925981Z",
     "iopub.status.idle": "2023-10-01T15:33:09.269379Z",
     "shell.execute_reply": "2023-10-01T15:33:09.268765Z"
    },
    "papermill": {
     "duration": 14.351624,
     "end_time": "2023-10-01T15:33:09.271459",
     "exception": false,
     "start_time": "2023-10-01T15:32:54.919835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install transformers\n",
    "import torch\n",
    "from transformers import DebertaTokenizer, DebertaForSequenceClassification, DebertaConfig, AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823ff4ae",
   "metadata": {
    "papermill": {
     "duration": 0.004816,
     "end_time": "2023-10-01T15:33:09.281723",
     "exception": false,
     "start_time": "2023-10-01T15:33:09.276907",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ÇALIŞTIRMAYI BAŞARDIM AŞAĞIDAKİ KOD İLE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeeb65d9",
   "metadata": {
    "papermill": {
     "duration": 0.004933,
     "end_time": "2023-10-01T15:33:09.291720",
     "exception": false,
     "start_time": "2023-10-01T15:33:09.286787",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Modeli yükle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "901e0544",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-01T15:33:09.303735Z",
     "iopub.status.busy": "2023-10-01T15:33:09.302858Z",
     "iopub.status.idle": "2023-10-01T15:33:13.897508Z",
     "shell.execute_reply": "2023-10-01T15:33:13.896644Z"
    },
    "papermill": {
     "duration": 4.602699,
     "end_time": "2023-10-01T15:33:13.899355",
     "exception": false,
     "start_time": "2023-10-01T15:33:09.296656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/deberta-v3-small/deberta-v3-small and are newly initialized: ['classifier.weight', 'classifier.bias', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# X ve y'yi ayırın\n",
    "X = filtered_summaries_train['cleaned_text'].values\n",
    "y = filtered_summaries_train[['content', 'wording']].values\n",
    "\n",
    "# Model ve Tokenizer'ı yükleyin\n",
    "model_name = '/kaggle/input/deberta-v3-small/deberta-v3-small'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)  # İki etiket olduğunu varsayalım"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d688ca0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-01T15:33:13.911546Z",
     "iopub.status.busy": "2023-10-01T15:33:13.910597Z",
     "iopub.status.idle": "2023-10-01T15:33:13.980667Z",
     "shell.execute_reply": "2023-10-01T15:33:13.979478Z"
    },
    "papermill": {
     "duration": 0.077832,
     "end_time": "2023-10-01T15:33:13.982602",
     "exception": false,
     "start_time": "2023-10-01T15:33:13.904770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Verileri tokenize edin ve tensörlere çevirin\n",
    "def tokenize_data(texts, labels):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for text in texts:\n",
    "        encoded = tokenizer(\n",
    "            text,\n",
    "            padding=\"max_length\",  # Metni maksimum token sayısına göre doldurun\n",
    "            truncation=True,        # Uzun metinleri kırpın\n",
    "            max_length=400,         # Maksimum token sayısını ayarlayın\n",
    "            return_tensors=\"pt\"    # PyTorch tensörleri olarak döndürün\n",
    "        )\n",
    "        \n",
    "        input_ids.append(encoded[\"input_ids\"])\n",
    "        attention_masks.append(encoded[\"attention_mask\"])\n",
    "    \n",
    "    return torch.cat(input_ids, dim=0), torch.cat(attention_masks, dim=0), torch.tensor(labels)\n",
    "\n",
    "input_ids, attention_masks, labels = tokenize_data(X, y)\n",
    "\n",
    "# Veriyi tensör veri kümesine dönüştürün\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "batch_size = 32\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a871c475",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-01T15:33:13.994342Z",
     "iopub.status.busy": "2023-10-01T15:33:13.994027Z",
     "iopub.status.idle": "2023-10-01T15:42:13.721503Z",
     "shell.execute_reply": "2023-10-01T15:42:13.720359Z"
    },
    "papermill": {
     "duration": 539.735688,
     "end_time": "2023-10-01T15:42:13.723625",
     "exception": false,
     "start_time": "2023-10-01T15:33:13.987937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Step 1/3 - Loss: 0.2205\n",
      "Epoch 1/5 - Step 2/3 - Loss: -0.1261\n",
      "Epoch 1/5 - Step 3/3 - Loss: -0.3309\n",
      "Epoch 1/5 - Loss: -0.0788\n",
      "Epoch 2/5 - Step 1/3 - Loss: -0.1661\n",
      "Epoch 2/5 - Step 2/3 - Loss: 0.0898\n",
      "Epoch 2/5 - Step 3/3 - Loss: 0.0389\n",
      "Epoch 2/5 - Loss: -0.0125\n",
      "Epoch 3/5 - Step 1/3 - Loss: 0.0749\n",
      "Epoch 3/5 - Step 2/3 - Loss: -0.2423\n",
      "Epoch 3/5 - Step 3/3 - Loss: 0.2312\n",
      "Epoch 3/5 - Loss: 0.0213\n",
      "Epoch 4/5 - Step 1/3 - Loss: -0.2322\n",
      "Epoch 4/5 - Step 2/3 - Loss: 0.2412\n",
      "Epoch 4/5 - Step 3/3 - Loss: -0.1701\n",
      "Epoch 4/5 - Loss: -0.0537\n",
      "Epoch 5/5 - Step 1/3 - Loss: -0.2888\n",
      "Epoch 5/5 - Step 2/3 - Loss: 0.1380\n",
      "Epoch 5/5 - Step 3/3 - Loss: 0.1870\n",
      "Epoch 5/5 - Loss: 0.0121\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Modeli eğitin\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "model.train()\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    step = 0  # Eğitim adımını izlemek için bir sayaç ekleyin\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Her adım sonunda ilerlemeyi yazdırın\n",
    "        print(f\"Epoch {epoch + 1}/{epochs} - Step {step + 1}/{len(dataloader)} - Loss: {loss.item():.4f}\")\n",
    "        step += 1\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs} - Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# İlk olarak content'i tahmin et\n",
    "model.eval()\n",
    "predictions_content = []\n",
    "true_labels_content = []\n",
    "\n",
    "for batch in dataloader:\n",
    "    input_ids, attention_mask, labels = batch\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    logits = outputs.logits\n",
    "    predicted_labels = torch.argmax(logits, dim=1).tolist()\n",
    "    true_labels_content.extend(labels.tolist())\n",
    "    predictions_content.extend(predicted_labels)\n",
    "\n",
    "# Şimdi wording'i tahmin et (aynı dataloader kullanılabilir)\n",
    "model.eval()\n",
    "predictions_wording = []\n",
    "true_labels_wording = []\n",
    "\n",
    "for batch in dataloader:\n",
    "    input_ids, attention_mask, labels = batch\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    logits = outputs.logits\n",
    "    predicted_labels = torch.argmax(logits, dim=1).tolist()\n",
    "    true_labels_wording.extend(labels.tolist())\n",
    "    predictions_wording.extend(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98d9cc25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-01T15:42:13.737491Z",
     "iopub.status.busy": "2023-10-01T15:42:13.737103Z",
     "iopub.status.idle": "2023-10-01T15:43:14.509116Z",
     "shell.execute_reply": "2023-10-01T15:43:14.508028Z"
    },
    "papermill": {
     "duration": 60.787329,
     "end_time": "2023-10-01T15:43:14.517291",
     "exception": false,
     "start_time": "2023-10-01T15:42:13.729962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (Content): 1.0049\n",
      "Mean Squared Error (Wording): 1.0049\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# İlk olarak content'i tahmin et\n",
    "model.eval()\n",
    "predictions_content = []\n",
    "true_labels_content = []\n",
    "\n",
    "for batch in dataloader:\n",
    "    input_ids, attention_mask, labels = batch\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    logits = outputs.logits\n",
    "    predicted_labels = logits.squeeze().tolist()  # Regresyon çıktısı olduğu için squeeze ve listeye çeviriyoruz\n",
    "    true_labels_content.extend(labels.tolist())\n",
    "    predictions_content.extend(predicted_labels)\n",
    "\n",
    "# Şimdi wording'i tahmin et (aynı dataloader kullanılabilir)\n",
    "model.eval()\n",
    "predictions_wording = []\n",
    "true_labels_wording = []\n",
    "\n",
    "for batch in dataloader:\n",
    "    input_ids, attention_mask, labels = batch\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    logits = outputs.logits\n",
    "    predicted_labels = logits.squeeze().tolist()  # Regresyon çıktısı olduğu için squeeze ve listeye çeviriyoruz\n",
    "    true_labels_wording.extend(labels.tolist())\n",
    "    predictions_wording.extend(predicted_labels)\n",
    "\n",
    "# MSE hesaplamak için\n",
    "mse_content = mean_squared_error(true_labels_content, predictions_content)\n",
    "mse_wording = mean_squared_error(true_labels_wording, predictions_wording)\n",
    "\n",
    "print(f\"Mean Squared Error (Content): {mse_content:.4f}\")\n",
    "print(f\"Mean Squared Error (Wording): {mse_wording:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7acce0c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-01T15:43:14.532847Z",
     "iopub.status.busy": "2023-10-01T15:43:14.532462Z",
     "iopub.status.idle": "2023-10-01T15:43:14.542500Z",
     "shell.execute_reply": "2023-10-01T15:43:14.541354Z"
    },
    "papermill": {
     "duration": 0.01986,
     "end_time": "2023-10-01T15:43:14.544081",
     "exception": false,
     "start_time": "2023-10-01T15:43:14.524221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content RMSE: 1.002429876302063\n",
      "Wording RMSE: 1.002429876302063\n",
      "MCRMSE: 1.002429876302063\n",
      "Compt Score: 1.002429876302063\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Verileriniz\n",
    "content_true = true_labels_content  # Content gerçek değerler\n",
    "wording_true = true_labels_wording  # Wording gerçek değerler\n",
    "content_pred = predictions_content   # Content tahmin değerler\n",
    "wording_pred = predictions_wording   # Wording tahmin değerler\n",
    "\n",
    "def compute_mcrmse(content_true, content_pred, wording_true, wording_pred):\n",
    "    # Her iki sütun için RMSE hesaplamaları yapın\n",
    "    content_rmse = np.sqrt(mean_squared_error(content_true, content_pred))\n",
    "    wording_rmse = np.sqrt(mean_squared_error(wording_true, wording_pred))\n",
    "    \n",
    "    # Ortalama RMSE hesaplayın\n",
    "    mcrmse = (content_rmse + wording_rmse) / 2.0\n",
    "    \n",
    "    return {\n",
    "        \"content_rmse\": content_rmse,\n",
    "        \"wording_rmse\": wording_rmse,\n",
    "        \"mcrmse\": mcrmse,\n",
    "    }\n",
    "\n",
    "# MCRMSE sonuçlarını hesaplayın\n",
    "mcrmse_result = compute_mcrmse(content_true, content_pred, wording_true, wording_pred)\n",
    "\n",
    "# MCRMSE sonuçlarını yazdırın\n",
    "print(\"Content RMSE:\", mcrmse_result[\"content_rmse\"])\n",
    "print(\"Wording RMSE:\", mcrmse_result[\"wording_rmse\"])\n",
    "print(\"MCRMSE:\", mcrmse_result[\"mcrmse\"])\n",
    "\n",
    "def compt_score(content_true, content_pred, wording_true, wording_pred):\n",
    "    content_score = mean_squared_error(content_true, content_pred)**(1/2)\n",
    "    wording_score = mean_squared_error(wording_true, wording_pred)**(1/2)\n",
    "    \n",
    "    return (content_score + wording_score)/2\n",
    "\n",
    "# Compt_score hesaplama fonksiyonunu kullanarak sonuçları alın\n",
    "compt_result = compt_score(content_true, content_pred, wording_true, wording_pred)\n",
    "\n",
    "# Compt_score sonucunu yazdırın\n",
    "print(\"Compt Score:\", compt_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fcc678e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-01T15:43:14.557682Z",
     "iopub.status.busy": "2023-10-01T15:43:14.557338Z",
     "iopub.status.idle": "2023-10-01T15:43:14.566315Z",
     "shell.execute_reply": "2023-10-01T15:43:14.565505Z"
    },
    "papermill": {
     "duration": 0.017816,
     "end_time": "2023-10-01T15:43:14.568167",
     "exception": false,
     "start_time": "2023-10-01T15:43:14.550351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Content ve wording tahminlerinin ortalamasını alın\n",
    "average_content = np.mean(predictions_content)\n",
    "average_wording = np.mean(predictions_wording)\n",
    "\n",
    "# Mevcut \"sub\" dosyasına tahminleri ekleyin\n",
    "sub['content'] = average_content\n",
    "sub['wording'] = average_wording\n",
    "\n",
    "# Güncellenmiş gönderim dosyasını kaydedin\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 676.417841,
   "end_time": "2023-10-01T15:43:17.463904",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-01T15:32:01.046063",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
